# 校园网搜索引擎 开发文档

## 数据库设计

#### Webpage info

| ID(AI) | linkid | page     | title     | content  |      | total | note |
| ------ | ------ | -------- | --------- | -------- | ---- | ----- | ---- |
| 1      | 1      | \<html\> | \<title\> | \<body\> |      | 1000  | test |

#### Hash table

| Id(AI) | link    | include | weight | Update_time | (type) |
| ------ | ------- | ------- | ------ | ----------- | ------ |
| 1      | http:// | 100111  |        | datetime    | (0/1)  |

#### wordlist

| Id(AI) | index   | count | note |
| ------ | ------- | ----- | ---- |
| 1      | 1100111 | 5     | test |

## 爬取网页

- Read from database.hash_table to get address & id
- Send Requests
- Judge the cases
  - if outside the campus -> type = 1(update_time = min)
- insert page data into Webpage_info
- insert update_time/type into Hash_table where id = id

## 分析网页

#### 解析HTML

- read page, id, linkid from Webpage_info
- Beautiful Soup analyze page -> title, content
- insert new links into Hash_table & update include, update_time where linkid
- insert into Webpage_info title, content where id

#### 文本分词

- jieba分词: content -> a word list -> wordlist

  > Python中文分词组件 "Jieba" 
  >
  > 支持三种分词模式：
  >
  > ​	精确模式，试图将句子最精确地切开，适合文本分析；
  >
  > ​	全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；
  >
  > ​	搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。

#### 定期计算权重(待完善)

- 通过迭代的方式定期计算权重(Hash_table.Weight)

## 查询数据库 & 前端

- Nginx + PHP + SQLite 轻型框架，搭载在Rapiberry 3B上
- Bootstrap框架构建前端页面

## 原理&公式(待完善)

#### 词权重

​	根据每个词在网页中出现的次数以及包含该词汇的网页确定词的权重。出现次数越多则权重越大，即在搜索时相关性越大。

#### 网页权重

​	来自所有指向其的其他网页的权重之和。	

## 参考资料

- 《数学之美》 吴军 人民邮电出版社 (重点为7 - 11章)

  - 《布尔代数和搜索引擎的索引》
  - 《贾里尼克和现代语言处理》
  - 《图论和网络爬虫》
  - 《PageRank——Google的民主表决式网页排名技术》
  - 《如何确定网页和查询的相关性》

- [简易搜索引擎(Python)](http://blkstone.github.io/2015/12/06/PySearchEngine/)

- [python搜索引擎实现](http://www.voidcn.com/article/p-hjpmifud-ss.html)

- [Python中文分词组件 jieba](https://www.oschina.net/p/jieba)

- [SQLite教程 - 菜鸟论坛](http://www.runoob.com/sqlite)

  ​

